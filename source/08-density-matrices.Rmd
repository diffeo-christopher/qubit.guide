# Density matrices {#density-matrices}

> About **density matrices**, and how they help to solve the problem introduced by entangled states, as well as how they let us talk about mixtures and subsystems.
> Also a first look at the **partial trace**.

<div class="video" title="Problems with state vectors" data-videoid="7HAqkivzt-I"></div>

<div class="video" title="Overview" data-videoid="5hiJRbIFKf4"></div>

We cannot always assign a definite state vector to a quantum system.
It may be that the system is part of a composite system that is in an entangled state, or it may be that our knowledge of the preparation of a particular system is insufficient to determine its state --- for example, someone may prepare a particle in one of the states $\ket{\psi_1}, \ket{\psi_2}, \ldots, \ket{\psi_n}$, with (respective) probabilities $p_1, p_2, \ldots, p_n$, and then give it to us without telling us which state $\ket{\psi_k}$ it's actually in.
Nevertheless, in either case we are able to make statistical predictions about the outcomes of measurements performed on the system using a more general description of quantum states.

We have already mentioned that the existence of entangled states leads to an obvious question: if we cannot attribute a state vectors to an individual quantum system, then how should we describe its quantum state?
In this chapter we will introduce an alternate description of quantum states that can be applied both to a composite system and to any of its subsystems.
Our new mathematical tool is called a **density operator**.^[If we choose a particular basis, operators become matrices. Throughout this book we use both terms (density *operators* and density *matrices*) pretty interchangeably.]
We will start with the density operator as a description of the mixture of quantum states, and will then discuss the partial trace, which is a unique operation that takes care of the reduction of a density operator of a composite system to density operators of its components.





## Definitions {#density-operator-definitions}

<div class="video" title="Density operators" data-videoid="pyTxPQLy6SE"></div>

If you are an impatient, more mathematically minded person, who feels most comfortable when things are properly defined right from the beginning, here is your definition.
Recall that a Hermitian matrix $M$ is said to be **non-negative**, or **positive semi-definite**, if $\braket{v}{M|v}\geq 0$ for any vector $\ket{v}$, or if all of its eigenvalues are non-negative, or if^[(This is called a **Cholesky factorization**.)] there exists another matrix $A$ such that $M=A^\dagger A$.

::: {.idea latex=""}
A **density operator** $\rho$ on a Hilbert space $\mathcal{H}$ is a non-negative Hermitian operator with trace equal to one:

- **Hermitian:** $\rho^\dagger=\rho$
- **Non-negative:** $\braket{v}{\rho|v}\geq0$ for all $\ket{v}$
- **Trace one:** $\tr\rho=1$.
:::

It follows that any density operator $\rho$ can always be diagonalised, and that the eigenvalues^[Note that these properties are exactly saying that we can interpret the eigenvalues as *probabilities*.] are all real, non-negative, and sum to $1$.
Moreover, given two density operators $\rho_1$ and $\rho_2$, we can always construct another density operator as a **convex sum** of the two:
$$
  \rho = p_1\rho_1 + p_2\rho_2
$$
where $p_1,p_2\geq0$ are such that $p_1+p_2=1$.
You should check that the resulting $\rho$ has all the defining properties of a density matrix, i.e. that it is Hermitian, non-negative, and that its trace is $1$.
This means that density operators form a **convex set**: a subset of a vector space is said to be **convex** if, for any two points in the subset, the straight line segment joining them is also entirely contained inside the subset.

An important example of a density operator is a rank-one projector:^[Recall that the rank of a matrix is equal to the number of its non-zero eigenvalues, or (equivalently) the dimension of its image.]
any quantum state that can be described by the state vector $\ket{\psi}$ can be also described by the density operator $\rho=\proj{\psi}$; such states are called **pure states**.
Pure states are the extremal points in the convex set of density operators: they cannot be expressed as a non-trivial convex sum of other elements in the set.
In contrast, all other states, called **mixed states**, can be always written as the convex sum of pure states: $\sum_i p_i \proj{\psi_i}$ for some $p_i\geq 0$ with $\sum_i p_i=1$.

::: {.technical title="Convex spaces" latex="{Convex spaces}"}
Convex spaces show up in many areas of mathematics: combinatorists and discrete geometers are often interested in [**convex polytopes**](https://en.wikipedia.org/wiki/Convex_polytope), and the special case of [**simplices**](https://en.wikipedia.org/wiki/Simplex) is even more fundamental, turning in up in algebraic topology, higher algebraic geometry, and, more generally, [higher category theory](https://en.wikipedia.org/wiki/Higher_category_theory).
Closer to what we are studying, the notion of [**entropy**](https://en.wikipedia.org/wiki/Entropy_(information_theory)) in (classical) information theory is somehow inherently convex (see e.g. arXiv:[1106.1791](https://arxiv.org/abs/1106.1791)).

The specific type of convex polytope that we are interested in turns out to be a [**convex hull**](https://en.wikipedia.org/wiki/Convex_hull), which are also found all throughout mathematics.
:::

Now that we have settled the mathematical essentials, we will turn to physical applications.





## Statistical mixtures

<div class="video" title="Statistical mixtures of states" data-videoid="OMIN_H-n-Ac"></div>

Let us start with probability distributions^[For brevity, we often simply say "**probability distribution**" to mean "a finite set of non-negative real numbers $p_k$ such that $\sum_k p_k=1$".] over state vectors.
Suppose Alice prepares a quantum system and hands it over to Bob, who subsequently measures observable $M$.
If Alice's preparation is described by a state vector $\ket{\psi}$, then, quantum theory declares, the average value of any observable $M$ is given by $\braket{\psi}{M|\psi}$, which we have previously also written as^[If $M$ is one of the orthogonal projectors $P_k$ describing the measurement, then the average $\av{P_k}$ is the probability of the outcome $k$ associated with this projector.]
$$
  \av{M} = \braket{\psi}{M|\psi} = \tr M\proj{\psi}.
$$

This way of expressing the average value makes a clear separation between the contributions from the state preparation and from the choice of the measurement.
We have two operators inside the trace: $\proj{\psi}$ describes the state preparation, and $M$ describes the measurement.

Now, suppose Alice prepares the quantum system in one of the (normalised, but not necessarily orthogonal) states $\ket{\psi_1},\ldots,\ket{\psi_m}$, choosing state $\ket{\psi_i}$ with probability $p_i$.
She then hands the system to Bob without telling him which state she chose.
We call this situation a **(statistical) mixture of the states** $\ket{\psi_i}$, or a **mixed state** for short.^[A pure state can be seen as a special case of a mixed state, where all but one the probabilities $p_i$ equal zero. So by talking about mixed states, we're still able to talk about everything that we've already seen up to this point.]

::: {.idea latex=""}
It is important to note that a mixture of states is very different from a superposition of states: a superposition *always* yields a definite state vector, whereas a mixture does *not*, and so must be described by a density operator.
:::

Let's be extra clear about this distinction between superpositions and statistical mixtures.
If Alice had prepared the system in the *superposition* $\sum_i p_i\ket{\psi_i}$, then both her *and* Bob would describe it by the state vector $\sum_i p_i\ket{\psi_i}$.
If she instead follows the above random procedure, then *she* knows that it is simply described by the state vector $\ket{\psi_i}$, but the best "description"^[This description is not one that we have seen before --- it's not a linear combination of kets, but instead a linear combination of *projectors*!] available to *Bob* is $\sum_i p_i\proj{\psi_i}$, as we will now justify.

What Bob *does* know is the ensemble of states $\ket{\psi_1},\ldots,\ket{\psi_m}$ as well as the corresponding probability distribution $p_1,\ldots,p_m$.
Using this, he can calculate $\av{M}$ as follows:
$$
  \begin{aligned}
    \av{M}
    &= \sum_i p_i\left( \tr M\proj{\psi_i} \right)
  \\&= \tr M \left( \sum_i p_i\proj{\psi_i} \right)
  \\&=\tr M\rho
  \end{aligned}
$$
where we have simply defined $\rho=\sum_i p_i\proj{\psi_i}$.
As before, we have two operators under the trace: $\rho=\sum_i p_i\proj{\psi_i}$, which pertains to the state preparation, and $M$, which describes the measurement.
We shall call the operator
$$
  \rho = \sum_i p_i \proj{\psi_i}
$$
the **associated density operator**, since it has all the defining properties of a density operator (it is a convex sum of rank-one projectors).
It depends on the constituent states $\ket{\psi_i}$ and their probabilities, and it describes our ignorance about the state preparation.
Conversely, given a density operator $\rho$, then we call a set $\{(p_i,\proj{\psi_i})\}$ a **convex decomposition** if it expresses $\rho$ as a convex sum of rank-one projectors, i.e. if $\rho=\sum_i p_i\proj{\psi_i}$.

Once we have $\rho$ we can make statistical predictions: we have just shown that, for any observable $M$, its expected value is given by
$$
  \av{M} = \tr M\rho.
$$
So the exact composition of the mixture does not enter this formula: for computing the statistics associated with any observable property of a system, all that matters is the density operator itself, but *not* its decomposition into the mixture of states.
This is important because any given density operator, with the remarkable exception of a pure state, can arise from many different mixtures of pure states.
Consider, for example, the following three scenarios:

1. Alice flips a fair coin.
    If the result is heads then she prepares the qubit in the state $\ket{0}$, and if the result is tails then she prepares the qubit in the state $\ket{1}$.
    She gives Bob the qubit without revealing the result of the coin-flip.
    Bob's  knowledge of the qubit is described by the density matrix
    $$
      \frac{1}{2}\proj{0} + \frac{1}{2}\proj{1}
      = \begin{bmatrix}
        \frac{1}{2} & 0
      \\0 & \frac{1}{2}
      \end{bmatrix}.
    $$

2. Alice flips a fair coin.
    If the result is heads then she prepares the qubit in the state $\ket{+}\coloneqq\frac{1}{\sqrt{2}}(\ket{0}+\ket{1})$, and if the result is tails then she prepares the qubit in the state $\ket{-}\coloneqq\frac{1}{\sqrt{2}}(\ket{0}-\ket{1})$.
    Bob's knowledge of the qubit is now described by the density matrix
    $$
      \begin{aligned}
        \frac{1}{2}\proj{+} + \frac{1}{2}\proj{-}
        &=
        \frac{1}{2}
        \begin{bmatrix}
        \frac{1}{2} & \frac{1}{2}
        \\\frac{1}{2} & \frac{1}{2}
        \end{bmatrix}
        +\frac{1}{2}
        \begin{bmatrix}
        \frac{1}{2} & -\frac{1}{2}
        \\-\frac{1}{2} & \frac{1}{2}
        \end{bmatrix}
      \\&=
        \begin{bmatrix}
        \frac{1}{2} & 0
        \\0 & \frac{1}{2}
        \end{bmatrix}.
      \end{aligned}
    $$

3. Alice flips a fair coin, having already picked an arbitrary pair of orthonormal states $\ket{u_1}$ and $\ket{u_2}$.
    If the result is heads then she prepares the qubit in the state $\ket{u_1}$, and if the result is tails then she prepares the qubit in the state $\ket{u_2}$.
    Since any two orthonormal states of a qubit form a complete basis, the mixture $\frac{1}{2}\proj{u_1}+\frac{1}{2}\proj{u_2}$ gives $\frac{1}{2}\id$.

As you can see, these three different preparations yield precisely the same density matrix and are thus *statistically indistinguishable*.
In general, two different mixtures can be distinguished (in a statistical, experimental sense) if and only if they yield different density matrices.
In fact, the optimal way of distinguishing quantum states with different density operators is still an active area of research.





## Instructive examples {#instructive-examples}

::: {.idea latex=""}
The density matrix corresponding to the state vector $\ket{\psi}$ is the rank-one projector $\proj{\psi}$.
:::

This correspondence is well defined: each $\ket{\psi}$ gives rise to a distinct density matrix, and the fact that we ignore global phases for state vectors doesn't introduce any ambiguity for the density matrices, since $\ket{\psi}$ and $e^{i\phi}\ket{\psi}$ give the same density matrix.

Let's consider two examples, seeing again how superpositions differ from statistical mixtures.

1. If Alice prepares a qubit in the superposition state $\ket{\psi} = \alpha\ket{0} + \beta\ket{1}$ then the corresponding density matrix is the projector
    $$
      \proj{\psi}
      = \begin{bmatrix}
        |\alpha|^2 & \alpha\beta^\star
      \\\alpha^\star\beta & |\beta|^2
      \end{bmatrix}.
    $$

2. You are given a qubit and you are told that it was prepared either in state $\ket{0}$ with probability $|\alpha|^2$ or in state $\ket{1}$ with probability $|\beta|^2$.
    In this case all you can say is that your qubit is in a mixed state described by the density matrix
    $$
      |\alpha|^2\proj{0} + |\beta|^2\proj{1}
      = \begin{bmatrix}
        |\alpha|^2 & 0
      \\0 & |\beta|^2
      \end{bmatrix}.
    $$

::: {.idea latex=""}
The density matrix corresponding to a statistical mixture of states $\ket{\psi_1},\ldots,\ket{\psi_n}$ with probability distribution $p_1,\ldots,p_n$ is the convex combination $\sum_i p_i\proj{\psi_i}$.
If the constituent states are orthogonal, then the density matrix is diagonal.
:::

Suppose you want to distinguish between preparations described by the density matrices in the above two examples.
Assume that you are given sufficiently many qubits, all identically prepared, i.e. either all described by the density matrix $\left[\begin{smallmatrix}|\alpha|^2&\alpha\beta^\star\\\alpha^\star\beta&|\beta|^2\end{smallmatrix}\right]$, or all described by the density matrix $\left[\begin{smallmatrix}|\alpha|^2&0\\0&|\beta|^2\end{smallmatrix}\right]$.
Which of the two measurements would you choose: the measurement in the standard basis $\{\ket{0},\ket{1}\}$, or the measurement in the basis $\{\ket{\psi},\ket{\psi^\perp}\}$ where $\ket{\psi^\perp}$ is orthonormal to $\ket{\psi}$?^[In fact, one of these two measurements is completely useless. **Exercise.** Which one, and why?]

In general, the diagonal entries of a density matrix describe the probability distributions on the set of basis vectors.
They must add up to one, which is why the trace of any density matrix is one.
The off-diagonal elements, often called **coherences**, signal departure from the classical probability distribution and quantify the degree to which a quantum system can witness interference (we will discuss this in detail later on).
The process in which off-diagonal entries go to zero is called **decoherence**.
$$
  \begin{bmatrix}
    |\alpha|^2 & \alpha\beta^\star
  \\\alpha^\star\beta & |\beta|^2
  \end{bmatrix}
  \longmapsto
  \begin{bmatrix}
    |\alpha|^2 & \varepsilon
  \\\varepsilon^\star & |\beta|^2
  \end{bmatrix}
  \longmapsto
  \begin{bmatrix}
    |\alpha|^2 & 0
  \\0 & |\beta|^2
  \end{bmatrix}
$$
For $\varepsilon = \alpha\beta^\star$ we have a pure quantum state ("full interference capability") and for $\varepsilon=0$ we have a classical probability distribution over the standard basis ("no interference capability").

3. Suppose that your qubit was prepared either in state $\alpha\ket{0} + \beta\ket{1}$ or in state $\alpha\ket{0} - \beta\ket{1}$, with equal probability.
    This means that your qubit is in a mixed state described by the density matrix
    $$
      \frac{1}{2}
      \begin{bmatrix}
        |\alpha|^2 & \alpha\beta^\star
      \\\alpha^\star\beta & |\beta|^2
      \end{bmatrix}
      +\frac{1}{2}
      \begin{bmatrix}
        |\alpha|^2 & -\alpha\beta^\star
      \\-\alpha^\star\beta & |\beta|^2
      \end{bmatrix}
      = \begin{bmatrix}
        |\alpha|^2 & 0
      \\0 & |\beta|^2
      \end{bmatrix}.
    $$

::: {.idea latex=""}
There is *no way* to tell the difference between the equally weighted mixture of $\alpha\ket{0}\pm\beta\ket{1}$ and a mixture of $\ket{0}$ and $\ket{1}$ with (respective) probabilities $|\alpha|^2$ and $|\beta|^2$.
:::

4. For *any* density matrix $\rho$, the most natural mixture that yields $\rho$ is its **spectral decomposition**: $\rho=\sum_i p_i\proj{u_i}$, with eigenvectors $\ket{u_i}$ and eigenvalues $p_i$.

5. If the states $\ket{u_1},\ldots,\ket{u_n}$ form an orthonormal basis, and each occurs with equal probability $1/n$, then the resulting density matrix is proportional to the identity:
    $$
      \frac{1}{n}\sum_{i=1}^n \proj{\psi_i}
      = \frac{1}{n}\id.
    $$
    This is a **maximally mixed** state.
    For qubits, any pair of orthogonal states taken with equal probabilities gives the maximally mixed state $\frac{1}{2}\id$.

::: {.idea latex=""}
A state is said to be **maximally mixed** if the outcomes of *any* measurement are completely random.
:::

It is often convenient to write density operators in terms of projectors on states which are *not* normalised, incorporating the probabilities into the length of the state vector:
$$
  \rho = \sum_i\proj{\tilde\psi_i}
$$
where $\ket{\tilde\psi_i} = \sqrt{p_i}\ket{\psi_i}$, i.e. $p_i=\braket{\tilde\psi_i}{\tilde\psi_i}$.
This form is more compact, but you have to remember that the state vectors are *not* normalised.
We tend to mark such states with the tilde, e.g. $\ket{\tilde\psi}$, but you may have your own way to remember.





## The Bloch ball

<div class="video" title="The Bloch ball" data-videoid="qmj0aD8pYho"></div>

We have already talked in some depth about the Bloch sphere, but now that we are considering density operators (which are strictly more general than state vectors), we are actually interested in the Bloch *ball*,^[Physicists often still refer to the Bloch *ball* as the Bloch *sphere*, even though it really is a ball now, not a sphere.] i.e. not just the sphere of vectors of magnitude $1$, but instead the ball of vectors of magnitude *less than or equal to* $1$.

An arbitrary $(2\times 2)$ Hermitian matrix has four real parameters and can be expanded in the basis $\{\id, \sigma_x, \sigma_y, \sigma_z\}$ consisting of the identity and the three Pauli matrices.
Since the Pauli matrices are traceless (i.e. their trace is equal to $0$), the coefficient of $\id$ in the expansion of a density matrix $\rho$ must be $\frac{1}{2}$, in order to have $\tr\rho=1$.
Thus $\rho$ may be expressed as
$$
  \begin{aligned}
    \rho
    &= \frac{1}{2}\left( \id +\vec{s}\cdot\vec{\sigma} \right)
  \\&= \frac{1}{2}
    \begin{bmatrix}
      1+s_z & s_x-is_y
    \\s_x+is_y & 1-s_z
    \end{bmatrix}.
  \end{aligned}
$$
where $\vec{s}=(s_x,s_y,s_z)$ and $\vec{\sigma}=(\sigma_x,\sigma_y,\sigma_z)$.
The vector $\vec{s}$ is called the **Bloch vector** for the density operator $\rho$.
Any real Bloch vector $\vec{s}$ defines a Hermitian operator $\rho$ with $\tr\rho=1$, but in order for $\rho$ to be a density operator it must *also* be non-negative.
Which Bloch vectors yield legitimate density operators?
That is, what does the non-negative condition on $\rho$ translate to in terms of the Bloch vector $\vec{s}$?

To answer this, let us compute the eigenvalues of $\rho$.
The trace of a matrix is equal to the *sum* of its eigenvalues, and the determinant is equal to the *product* of its eigenvalues.
We know that $\tr\rho=1$, and we can calculate $\det\rho$ from the matrix form above:
$$
  \begin{aligned}
    \det\rho
    &= \frac{1}{4}(1-s^2)
  \\&= \frac{1}{2}(1+s)\frac{1}{2}(1-s)
  \end{aligned}
$$
where $s=|\vec{s}|=\sqrt{|s_x|^2+|s_y|^2+|s_z|^2}$.
It follows that the two eigenvalues of $\rho$ are $\frac{1}{2}(1\pm s)$.
For $\rho$ to be non-negative, its eigenvalues have to be non-negative, and so $s$ (the length of the Bloch vector) cannot exceed $1$.

We can now visualise the convex set of $(2\times 2)$ density matrices as a unit ball in three-dimensional Euclidean space: the extremal points, which represent pure states, are the points on the boundary ($\vec{s}$ such that $s=1$), i.e. the surface of the ball (the Bloch sphere, which we have already seen!); the maximally mixed state $\id/2$ corresponds to $s=0$, i.e. the centre of the ball.
In general, the length of the Bloch vector $s$ can be thought of as the "purity" of a state.

One might hope that there is an equally simple visualisation of the density operators in higher dimensions.
Unfortunately, there is *not*: things become *much* more complicated, very quickly.

::: {.technical title="Bloch ball for qutrits" latex="{Bloch ball for qutrits}"}
Qubits are $2$-dimensional and give rise to the Bloch ball, which is a $3$-dimensional object.
In general, $n$-dimensional quantum systems give rise to $(n^2-1)$-dimensional state spaces, often denoted $\mathcal{Q}_n$; for $n=3$, where we study [**qutrits**](https://en.wikipedia.org/wiki/Qutrit), we would need to study an $8$-dimensional object $\mathcal{Q}_3$.

It turns out, quite surprisingly, that there exists a $3$-dimensional object that has many (but not all) of the properties that we would want from $\mathcal{Q}_3$.
For example, the rank-$1$ pure states form a connected set on the surface, which lies a maximum distance of $\sqrt{2}$ from the maximally mixed state $\frac13\id$; the other points on the surface correspond to rank-$1$ and rank-$2$ operators; the points strictly inside correspond to rank-$3$ (i.e. full rank) operators.
However, since it is only $3$-dimensional, it can never satisfy *all* the properties that we would like, since $\mathcal{Q}_3$ *has to be* $8$-dimensional.
Nevertheless, the construction is both interesting and useful (and very recent!) --- see C Eltschka, M Huber, S Morelli, and J Siewert, "The shape of higher-dimensional state space: Bloch-ball analog for a qutrit", *Quantum* **5** (2021), DOI: [10.22331/q-2021-06-29-485](https://doi.org/10.22331/q-2021-06-29-485).
:::


One has to be careful when trying to use the Bloch ball to talk about multiple qubits, precisely for the reason that "most" states are not separable states, but instead have some amount of entanglement.
If we have $n$ qubits, then we can describe the corresponding product state in terms of $n$ vectors in the Bloch ball, but this method only lets us describe *product* states of the $n$ qubits --- we saw in Section \@ref(separable-or-entangled) that, as $n$ grows larger, "most" states are *not* separable!

For example, say that we have a system with two qubits, and we wish to understand how they move around the Bloch sphere under some unitary evolution.
If our qubits are initially in state $\ket{a}\ket{b}$, then evolve to the state $U\ket{a}\ket{b}$.
Simple!
But now say that, before applying our unitary $U$, we first *rotated* the Bloch ball so that our qubits were in some other state $\ket{a'}\ket{b'}$, and *then* applied our unitary $U$ to this rotated state.
A natural question to ask is if there exists some rotation that takes the first result $U\ket{a}\ket{b}$ to the second result $U\ket{a'}\ket{b'}$.
In other words, if we denote our rotation by $R$, then does there exist a rotation $S$ such that $U\circ R = S\circ U$?

The answer is most definitely *no*, as shown by a reasonably simple example: consider the controlled-$\texttt{NOT}$ gate acting on two qubits initially in some state $\ket{0}\ket{\psi}$, and where the rotation $R$ takes $\ket{0}\ket{\psi}$ to $\ket{\psi'}\ket{0}$.
Then $(U\circ R)\ket{a}\ket{b}=\ket{\psi'}\ket{\psi'}$, and $U\ket{a}\ket{b}=\ket{0}\ket{\psi}$.
But we cannot transform the latter into the former by a simple rotation of the sphere, since the latter has two distinct Bloch vectors, whereas the former has a single repeated one, and rotations never "collapse" two distinct vectors into one.
The key point here is that the angles between the Bloch vectors can *change* upon applying unitary operations, and the amount by which they change can depend on the Bloch vectors themselves, whereas rotations keep these relative angles *constant*.



## Subsystems of entangled systems

<div class="video" title="Partial trace" data-videoid="L5HXMlpWAE8"></div>

Earlier, we claimed that one of the most important features of the density operator formalism is its ability to describe the quantum state of a subsystem of a composite system.
Let us now show you how this works.

Given a quantum state of the composite system $\mathcal{AB}$ described by some density operator $\rho_{\mathcal{AB}}$, we obtain **reduced** density operators $\rho_{\mathcal{A}}$ and $\rho_{\mathcal{B}}$ of the subsystems $\mathcal{A}$ and $\mathcal{B}$ (respectively) by the **partial trace**:
$$
  \begin{aligned}
    \rho_{\mathcal{AB}}
    &\longmapsto
    \rho_{\mathcal{A}}
    = \underbrace{\tr_{\mathcal{B}}\rho_{\mathcal{AB}}}_{\mathrm{partial\,trace\,over}\,\mathcal{B}}\qquad
  \\\rho_{\mathcal{AB}}
    &\longmapsto
    \rho_{\mathcal{B}}
    = \underbrace{\tr_{\mathcal{A}}\rho_{\mathcal{AB}}}_{\mathrm{partial\,trace\,over}\,\mathcal{A}}
  \end{aligned}
$$
We will revisit the notion of partial trace quite a few times, but for now we simply define the partial trace over $\mathcal{B}$ (or $\mathcal{A}$) first on a tensor product of two operators $A\otimes B$ as
$$
  \begin{aligned}
    \tr_{\mathcal{B}} (A\otimes B)
    &= A(\tr B)
  \\\tr_{\mathcal{A}} (A\otimes B)
    &= (\tr A) B,
  \end{aligned}
$$
and then extend to any operator on $\mathcal{H}_{\mathcal{A}}\otimes\mathcal{H}_{\mathcal{B}}$ by linearity.

Here is a simple example.
Suppose a composite system $\mathcal{AB}$ is in a pure entangled state $\ket{\psi_{\mathcal{AB}}}$.
We can always write this as
$$
  \ket{\psi_{\mathcal{AB}}}
  = \sum_{i} c_{i} \ket{a_i}\otimes\ket{b_i},
$$
where $\ket{a_i}$ and $\ket{b_j}$ are two orthonormal bases (e.g. the Schmidt bases, from Exercise \@ref(the-schmidt-decomposition)), and where $\sum_i |c_i|^2 = 1$ (due to the normalisation).
The corresponding density operator of the composite system is the projector $\rho_{\mathcal{AB}}= \proj{\psi_{\mathcal{AB}}}$, which we can write as
$$
  \rho_{\mathcal{AB}}
  = \proj{\psi_{\mathcal{AB}}}
  = \sum_{i,j} c_i c^\star_j \ket{a_i}\bra{a_j} \otimes \ket{b_i}\bra{b_j}
$$

Let us compute the reduced density operator $\rho_{\mathcal{A}}$ by taking the partial trace over $\mathcal{B}$:
$$
  \begin{aligned}
    \rho_{\mathcal{A}}
    &= \tr_{\mathcal{B}}\rho_{\mathcal{AB}}
  \\&= \tr_{\mathcal{B}} \proj{\psi_{\mathcal{AB}}}
  \\&= \tr_{\mathcal{B}} \sum_{i,j} c_i c^\star_j \ket{a_i}\bra{a_j} \otimes \ket{b_i}\bra{b_j}
  \\&= \sum_{i,j} c_i c^\star_j \ket{a_i}\bra{a_j}(\tr\ket{b_i}\bra{b_j})
  \\&= \sum_{i,j} c_i c^\star_j \ket{a_i}\bra{a_j} \underbrace{\braket{b_i}{b_j}}_{\delta_{ij}}
  \\& = \sum_{i} |c_i|^2 \proj{a_i}.
  \end{aligned}
$$
So, in the $\ket{a_i}$ basis, the reduced density matrix $\rho_{\mathcal{A}}$ is diagonal, with entries $p_i=|c_i|^2$.
Similarly, if we take the partial trace over $\mathcal{A}$, then we get $\rho_{\mathcal{B}}=\sum_{i} |c_i|^2 \proj{b_i}$.

In particular, if $\dim\mathcal{H}_{\mathcal{A}}=\dim\mathcal{H}_{\mathcal{B}}=d$, then the maximally mixed state
$$
  \ket{\psi_{\mathcal{AB}}}
  = \frac{1}{\sqrt{d}} \sum_{i}^d \ket{a_i}\ket{b_i},
$$
in the $(d\times d)$-dimensional Hilbert space $\mathcal{H}_{\mathcal{A}}\otimes\mathcal{H}_{\mathcal{B}}$ is such that the reduced density operators $\rho_{\mathcal{A}}$ and $\rho_{\mathcal{B}}$ are also the maximally mixed states of their respective subsystems: $\rho_{\mathcal{A}}=\rho_{\mathcal{B}}=\frac{1}{d}\id$.
It follows that the quantum states of individual qubits in any of the Bell states are maximally mixed: their density matrix is $\frac{1}{2}\id$.

A bipartite state such as
$$
  \frac{1}{\sqrt{2}} \left( \ket{00} + \ket{11} \right)
$$
guarantees *perfect correlations* when each qubit is measured in the standard basis: the two outcomes are "$0$ and $0$" or "$1$ and $1$" (which are equally likely), and we will never observe e.g. "$0$ and $1$", but the outcome of either *single*-qubit subsystem is completely random.





## Mixtures and subsystems

<div class="video" title="Indistinguishability of preparations" data-videoid="gRVODCksP74"></div>

<div class="video" title="Density operators and lack of knowledge" data-videoid="4DXtbLYhUL4"></div>

So far we have used density operators to describe two distinct situations: the statistical properties of mixtures of states, and the statistical properties of subsystems of composite systems.
In order to see the relationship between the two, consider a joint state of a bipartite system $\mathcal{AB}$, written in a product basis of $\mathcal{H}_{\mathcal{A}}\otimes\mathcal{H}_{\mathcal{B}}$ as
$$
  \begin{aligned}
    \ket{\psi_{\mathcal{AB}}}
    &= \sum_{i,j} c_{ij}\ket{a_i}\otimes\ket{b_j}
  \\&= \sum_{j} \ket{\widetilde\psi_j}\ket{b_j}
    = \sum_{j} \sqrt{p_j}\ket{\psi_j}\ket{b_j}
  \end{aligned}
$$
where $\ket{\widetilde\psi_j} = \sum_i c_{ij}\ket{a_i}$, which we can also write as $\sqrt{p_j}\ket{\psi_j}$ where the $\ket{\psi_j}$ are the normalised versions of the $\ket{\widetilde\psi_j}$, and $p_j=\braket{\widetilde\psi_j}{\widetilde\psi_j}$.

Then the partial trace over $\mathcal{B}$ gives the reduced density operator of subsystem $\mathcal{A}$:
$$
  \begin{aligned}
    \rho_{\mathcal{A}}
    &=\tr_{\mathcal{B}} \left( \sum_{i,j} \ket{\widetilde\psi_i}\bra{\widetilde\psi_j} \otimes \ket{b_i}\bra{b_j} \right)
  \\&= \sum_{i,j} \ket{\widetilde\psi_i}\bra{\widetilde\psi_j} (\tr\ket{b_i}\bra{b_j})
  \\&= \sum_{i,j} \ket{\widetilde\psi_i}\bra{\widetilde\psi_j} \braket{b_j}{b_i}
  \\&= \sum_{i} \ket{\widetilde\psi_i}\bra{\widetilde\psi_i}
    = \sum_{i} p_i \proj{\psi_i}.
  \end{aligned}
$$

Now let us see how $\rho_{\mathcal{A}}$ can be understood in terms of mixtures.
Imagine we place subsystems $\mathcal{A}$ and $\mathcal{B}$ in two separate labs, run by Alice and Bob, respectively.
Say Bob measures the $\mathcal{B}$ part in the $\ket{b_j}$ basis and obtains result $k$, which happens with probability $p_k$.
In doing so, he inevitably prepares subsystem $\mathcal{A}$ in the state $\ket{\psi_k}$:
$$
  \sum_{i=1} \sqrt{p_j}\ket{\psi_i}\ket{b_i}
  \overset{\mathrm{outcome}\,k}{\longmapsto}
  \ket{\psi_k}\ket{b_k}.
$$
Bob does not communicate the outcome of his measurement.
Thus, from Alice's perspective, Bob prepares a mixture of $\ket{\psi_1},\ldots,\ket{\psi_m}$, with probabilities $p_1,\ldots,p_m$, which means that Alice, who knows the joint state but *not* the outcomes of Bob's measurement, may associate density matrix $\rho_{\mathcal{A}}=\sum_i p_i\proj{\psi_i}$ with her subsystem $\mathcal{A}$.
This is the same $\rho_{\mathcal{A}}$ that we obtained before by taking the partial trace.

But suppose Bob chooses to measure his subsystem in some other basis.
Will it have any impact on Alice's statistical predictions?
Measurement in the new basis will result in a different mixture, but Alice's density operator *will not change*.

Say Bob chooses some basis $\ket{d_i}$ for his measurement.
Any two orthonormal bases are connected by some unitary transformation, and so we can write $\ket{b_i}=U\ket{d_i}$ for some^[In terms of components, $\ket{b_i}=\sum_j U_{ij}\ket{d_j}$] unitary $U$.
The joint state can now be expressed as
$$
  \begin{aligned}
    \ket{\psi_{\mathcal{AB}}}
    &= \sum_{i} \ket{\widetilde\psi_i}\ket{b_i}
  \\&= \sum_{i} \ket{\widetilde\psi_i} \left( \sum_j U_{ij}\ket{d_j} \right)
  \\&= \sum_j \underbrace{\left( \sum_i U_{ij}\ket{\widetilde\psi_i} \right)}_{\ket{\widetilde\phi_j}}\ket{d_j}
  \\&= \sum_j\ket{\widetilde\phi_j}\ket{d_j}.
  \end{aligned}
$$

If Bob measures in the $\ket{d_i}$ basis then he generates a new mixture of states $\ket{\phi_1},\ldots\ket{\phi_m}$, which are the normalised versions of $\ket{\widetilde\phi_1},\ldots\ket{\widetilde\phi_m}$, with each $\ket{\phi_k}$ occurring with probability $p_k=\braket{\widetilde\phi_k}{\widetilde\phi_k}$.
But this new mixture has exactly the same density operator as the previous one:
$$
  \begin{aligned}
    \sum_j\proj{\widetilde\phi_j}
    &= \sum_{i,j,l} U_{ij}\ket{\widetilde\psi_i}\bra{\widetilde\psi_l}U^\star_{lj}
  \\&= \sum_{i,l} \underbrace{\left(\sum_j U_{ij}U^\star_{lj}\right)}_{\delta_{il}}\ket{\widetilde\psi_i}\bra{\widetilde\psi_l}
  \\&= \sum_i\proj{\widetilde\psi_j}
  \end{aligned}
$$
where we use the fact that the $U_{ij}$ are the entries of a unitary matrix, and so $\sum_k U_{ik}U^\star_{jk}=\delta_{ij}$.
But this is exactly $\rho_{\mathcal{A}}$!
So does it really matter whether Bob actually performs the measurement or not?

*No --- it does not.*

After all, Alice and Bob may be many many miles away from each other, and if any of Bob's actions were to result in something that is physically detectable at Alice's lab, then this would amount to *instantaneous communication* between the two of them.

From the operational point of view it does not really matter whether the density operator represents our ignorance of the actual state (mixtures) or provides the only description we can have after discarding one part of an entangled state (partial trace).^[The two interpretations of density operators have filled volumes of academic journals. The terms **proper mixtures** and **improper mixtures** are used, mostly by philosophers, to describe the statistical mixture and the partial trace approach, respectively.]
In the former case, the system is in some definite pure state but we do not know which.
In contrast, when the density operator arises from tracing out irrelevant, or unavailable, degrees of freedom, the individual system cannot be thought to be in some definite state of which we are ignorant.
Philosophy aside, the fact that the two interpretations give exactly the same predictions is useful: switching back and forth between the two pictures often offers additional insights and may even simplify lengthy calculations.





## Partial trace, revisited

You can calculate the trace of a matrix by summing its diagonal entries.
Can you do something similar to calculate the partial trace of a density matrix?
Suppose someone writes down for you a density matrix of two qubits in the standard basis, $\{\ket{00}, \ket{01}, \ket{10}, \ket{11}\}$, and asks you to find the reduced density matrices of the individual qubits.
The tensor product structure of this $(4\times 4)$ matrix means that it is has a block form:
$$
  \rho_{\mathcal{AB}}
  = \left[
    \begin{array}{c|c}
      P & Q
    \\\hline
      R & S
    \end{array}
  \right]
$$
where $P,Q,R,S$ are $(2\times 2)$ sized sub-matrices.

The two partial traces can then be evaluated as^[Take any of the Bell states, write its $(4\times 4)$-density matrix explicitly, and then trace over each qubit. In each case you should get the maximally mixed state.]
$$
  \begin{aligned}
    \rho_{\mathcal{A}}
    &=
    \tr_{\mathcal{B}}\rho_{\mathcal{AB}}
    = \left[
      \begin{array}{c|c}
        \tr P & \tr Q
      \\\hline
        \tr R & \tr S
      \end{array}
    \right]
  \\\rho_{\mathcal{B}}
    &= \tr_{\mathcal{A}}\rho_{\mathcal{AB}}
    = P+S.
  \end{aligned}
$$

In general, for any matrix $\rho$ in $\mathcal{H}_{\mathcal{A}}\otimes\mathcal{H}_{\mathcal{B}}$ that is written *in the tensor product basis*, the partial trace over $\mathcal{A}$ is the sum of the diagonal block matrices, and the partial trace over $\mathcal{B}$ is the matrix in which the block sub-matrices are replaced by their traces --- see Figure \@ref(fig:visualising-partial-trace).

(ref:visualising-partial-trace-caption) Visualising the two partial traces of a matrix *written in the tensor product basis*.

```{r visualising-partial-trace,engine='tikz',engine.opts=list(template="latex/tikz2pdf.tex"),fig.width=8,fig.cap='(ref:visualising-partial-trace-caption)'}
\definecolor{primary}{RGB}{177,98,78}
\providecommand{\mqty}[1]{\begin{matrix}#1\end{matrix}}
\providecommand{\tr}{\operatorname{tr}}
\begin{equation*}
  \begin{array}{c}
    \left[
      \,
      \setlength\arraycolsep{0.4em}
      \begin{array}{c|c|c}
        \cellcolor{primary!20}\mqty{\cdot&\cdot\\\cdot&\cdot}
        & \mqty{\cdot&\cdot\\\cdot&\cdot}
        & \mqty{\cdot&\cdot\\\cdot&\cdot}
        \\\hline
        \mqty{\cdot&\cdot\\\cdot&\cdot}
        & \cellcolor{primary!20}\mqty{\cdot&\cdot\\\cdot&\cdot}
        & \mqty{\cdot&\cdot\\\cdot&\cdot}
        \\\hline
        \mqty{\cdot&\cdot\\\cdot&\cdot}
        & \mqty{\cdot&\cdot\\\cdot&\cdot}
        & \cellcolor{primary!20}\mqty{\cdot&\cdot\\\cdot&\cdot}
      \end{array}
      \,
    \right]
    \\ \\
    \tr_{\mathcal{A}}\rho
  \end{array}
  \qquad
  \begin{array}{c}
    \left[
      \,
      \setlength\arraycolsep{0.4em}
      \begin{array}{c|c|c}
        \mqty{\cellcolor{primary!20}\cdot&\cdot\\\cdot&\cellcolor{primary!20}\cdot}
        & \mqty{\cellcolor{primary!20}\cdot&\cdot\\\cdot&\cellcolor{primary!20}\cdot}
        & \mqty{\cellcolor{primary!20}\cdot&\cdot\\\cdot&\cellcolor{primary!20}\cdot}
      \\\hline
        \mqty{\cellcolor{primary!20}\cdot&\cdot\\\cdot&\cellcolor{primary!20}\cdot}
        & \mqty{\cellcolor{primary!20}\cdot&\cdot\\\cdot&\cellcolor{primary!20}\cdot}
        & \mqty{\cellcolor{primary!20}\cdot&\cdot\\\cdot&\cellcolor{primary!20}\cdot}
      \\\hline
        \mqty{\cellcolor{primary!20}\cdot&\cdot\\\cdot&\cellcolor{primary!20}\cdot}
        &\mqty{\cellcolor{primary!20}\cdot&\cdot\\\cdot&\cellcolor{primary!20}\cdot}
        & \mqty{\cellcolor{primary!20}\cdot&\cdot\\\cdot&\cellcolor{primary!20}\cdot}
      \end{array}
      \,
    \right]
    \\ \\
    \tr_{\mathcal{B}}\rho
  \end{array}
\end{equation*}
```

To better understand the partial trace, it helps to give a more abstract definition.
It turns out that the partial trace over $\mathcal{B}$ can be defined as the unique map $\rho_{\mathcal{AB}}\mapsto\rho_{\mathcal{A}}$ such that^[One can repeat the same argument for the partial trace over $\mathcal{A}$: it is the unique map $\rho_{\mathcal{AB}}\mapsto\rho_{\mathcal{B}}$ such that $\rho_{\mathcal{B}}$ satisfies $\tr [Y\rho_{\mathcal{B}}] = \tr [(1\otimes Y)\rho_{\mathcal{AB}}]$ for any observable $Y$ on $\mathcal{B}$.]
$$
  \tr[X\rho_{\mathcal{A}}] = \tr[(X\otimes\id)\rho_{\mathcal{AB}}]
  \tag{$\circledast$}
$$
holds for any observable $X$ acting on $\mathcal{A}$, where $\id$ is the identity operator acting on $\mathcal{B}$.
This condition ensures the consistency of statistical predictions: any observable $X$ on $\mathcal{A}$ can be viewed as an observable $X\otimes\id$ on the composite system $\mathcal{AB}$; when constructing $\rho_{\mathcal{A}}$, we had better make sure that for any observable $X$ the average value of $X$ in the state $\rho_{\mathcal{A}}$ is the same as the average value of $X\otimes\id$ in the state $\rho_{\mathcal{AB}}$.
This is exactly what the condition in $(\circledast)$ guarantees.

To show that our more ad-hoc definition of the partial trace agrees with this slightly more abstract one, consider again some state $\ket{\psi_{\mathcal{AB}}}$ written in the form
$$
  \begin{aligned}
    \ket{\psi_{\mathcal{AB}}}
    &= \sum_{i,j} c_{ij}\ket{a_i}\otimes\ket{b_j}
  \\&= \sum_{j} \ket{\widetilde\psi_j}\ket{b_j}
    = \sum_{j} \sqrt{p_j}\ket{\psi_j}\ket{b_j}.
  \end{aligned}
$$
Now assume that Alice measures some observable $X$ on her part of the system.
Such an observable can be thought of as $X\otimes\id$, acting on the entire system.
The expected value of *this* observable in the state $\ket{\psi_{\mathcal{AB}}}$ is, by definition, $\tr(X\otimes\id)\proj{\psi_{\mathcal{AB}}}$, and
$$
  \begin{aligned}
    \tr [(X\otimes \id) \rho_{\mathcal{AB}}]
    &= \tr \left[
        (X\otimes\id) \left(
          \sum_{i,j} \ket{\widetilde\psi_i}\bra{\widetilde\psi_j} \otimes \ket{b_i}\bra{b_j}
        \right)
      \right]
  \\&= \sum_{i,j} \left[
        \tr\left(X \ket{\widetilde\psi_i}\bra{\widetilde\psi_j}\right)
      \right]
      \underbrace{\left[\tr\left(\ket{b_i}\bra{b_j}\right)\right]}_{\delta_{ij}}
  \\&= \sum_i \tr \big[X \ket{\widetilde\psi_i}\bra{\widetilde\psi_i}\big]
  \\&= \tr \left[
      X \underbrace{\sum_i p_i\proj{\psi_i}}_{\rho_{\mathcal{A}} = \tr_{\mathcal{B}}\rho_{\mathcal{AB}}}
    \right]
  \\&= \tr [X\rho_{\mathcal{A}}]
  \end{aligned}
$$
as required.

We can also quickly prove why the partial trace is the *unique* map satisfying the condition $(\circledast)$.
Suppose that we had some arbitrary map $T$ satisfying this condition, i.e. such that
$$
  \tr[XT(\rho_{\mathcal{AB}})] = \tr[(X\otimes\id)\rho_{\mathcal{AB}}]
$$
for all density matrices $\rho_{\mathcal{AB}}$ and for all observables $X$ acting on $\mathcal{A}$.
Now, take some orthonormal (with respect to the Hilbert--Schmidt inner product $(A|B)=\frac{1}{2}\tr A^\dagger B$) basis $\{M_i\}$ of the space of Hermitian matrices.
Since the $M_i$ are Hermitian, the inner product $(M_i|T(\rho_{\mathcal{AB}}))$ is just^[We ignore the normalisation factor of $\frac{1}{2}$ in the Hilbert--Schmidt inner product here.] $\tr[M_iT(\rho_{\mathcal{AB}})]$.

So when we expand $T(\rho_{\mathcal{AB}})$ in this basis^[Expanding an operator in a basis might seem confusing at first, but this is really just the fact that (avoiding bra-ket notation for clarity) any vector $v$ in an inner product space with orthonormal basis $\{e_i\}$ can be expanded as $v=\sum_i\langle e_i,v\rangle e_i$, just applied to the specific case of a vector space of matrices, with the Hilbert--Schmidt inner product.] we get
$$
  \begin{aligned}
    T(\rho_{\mathcal{AB}})
    &= \sum_i (M_i|T(\rho_{\mathcal{AB}})) M_i
  \\&= \sum_i \tr[M_iT(\rho_{\mathcal{AB}})] M_i.
  \end{aligned}
$$
But now we can substitute in the condition that $T$ satisfies, giving
$$
  T(\rho_{\mathcal{AB}})
  = \sum_i \tr[(M_i\otimes\id)\rho_{\mathcal{AB}}] M_i.
$$
And we're done!
Indeed, if we had started with some other such map $T'$ then we would have arrived at the same expression, which is independent of our choice of $T$ or $T'$, whence $T=T'$.





## *Remarks and exercises* {#remarks-and-exercises-density-matrices}

### Some density operator calculations {#some-density-operator-calculations}

Consider two qubits in the state
$$
  \ket{\psi} =
  \frac{1}{\sqrt{2}}\left(
    \ket{0}\otimes\left(
      \sqrt{\frac23}\ket{0}
      - \sqrt{\frac13}\ket{1}
    \right)
    + \ket{1}\otimes\left(
      \sqrt{\frac23}\ket{0}
      + \sqrt{\frac13}\ket{1}
    \right)
  \right).
$$

1. What is the density operator $\rho$ of the two qubits corresponding to the state $\ket{\psi}$?
  Write it in Dirac notation, and then explicitly as a matrix in the computational basis $\{\ket{00},\ket{01},\ket{10},\ket{11}\}$.

2. Find the reduced density operators $\rho_1$ and $\rho_2$ of the first and second qubit, respectively.
  Again, write them in both Dirac notation as well as explicitly as a matrix in the computational basis.


### Purification of mixed states

<div class="video" title="Purification" data-videoid="PX0Qdmy9zdY"></div>

Given a mixed state $\rho$, a **purification** of $\rho$ is a pure state $\proj{\psi}$ of some potentially larger system such that $\rho$ is equal to a partial trace of $\proj{\psi}$.

1. Show that an arbitrary mixed state $\rho$ always has a purification.

2. Show that purification is unique up to unitary equivalence.

3. Let $\ket{\psi_1}$ and $\ket{\psi_2}$ in $\mathcal{H}_{\mathcal{A}}\otimes\mathcal{H}_{\mathcal{B}}$ be two pure states such that $\tr_{\mathcal{B}}\proj{\psi_1} = \tr_{\mathcal{B}}\proj{\psi_2}$.
  Show that $\ket{\psi_1} = \id\otimes U\ket{\psi_2}$ for some unitary operator $U$ on $\mathcal{H}_{\mathcal{B}}$.

Well done --- you have just proved the [**Schrödinger--HJW theorem**](https://en.wikipedia.org/wiki/Schr%C3%B6dinger%E2%80%93HJW_theorem)!


### Pure partial trace

Two qubits are in the state described by the density operator $\rho=\rho_{\mathcal{A}}\otimes\rho_{\mathcal{B}}$.
What is the partial trace of $\rho$ over each qubit?


### Maximally Bell

What is the density matrix corresponding to two qubits prepared in the mixture of the Bell state $\Phi^+=\frac{1}{\sqrt{2}}(\ket{00}+\ket{11})$ and the maximally mixed state^[The maximally mixed state of two qubits is described by a $(4\times 4)$ matrix in $\mathcal{H}_{\mathcal{A}}\otimes\mathcal{H}_{\mathcal{B}}$.], both with equal probability $\frac{1}{2}$?


### Spectral decompositions and common eigenbases

::: {.todo latex=""}
<!-- TO-DO -->
:::
